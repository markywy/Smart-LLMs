import argparse
import datetime
import os
import os.path as osp

from smartllm.agents import AGENT_TYPES, SIMULATORS
from smartllm.dataloader import DataLoader
from smartllm.evaluators import EVALUATORS
from smartllm.utils import llm_register_args

# format YYYY_MM_DD__HH_MM_SS
NOW = datetime.datetime.now().strftime("%Y_%m_%d__%H_%M_%S")

EXECUTE_SCRIPT = "./scripts/emulate.py"
EVALUATE_SCRIPT = "./scripts/evaluate.py"
READRESULTS_SCRIPT = "./scripts/helper/read_eval_results.py"

parser = argparse.ArgumentParser()
llm_register_args(parser, prefix="agent")
DataLoader.register_args(parser, default_input_path="./assets/all_cases.json")
parser.add_argument("--dump-dir", "-du", type=str, default="./dumps/trajectories")
parser.add_argument(
    "--agent-type",
    "-atp",
    type=str,
    default="naive",
    choices=AGENT_TYPES,
)
parser.add_argument(
    "--simulator-type",
    "-stp",
    type=str,
    default="adv_thought",
    choices=list(SIMULATORS.keys()),
)
parser.add_argument("--batch-size", "-bs", type=int, default=None, help="batch size")
parser.add_argument("--auto", "-auto", action="store_true", help="auto mode")
args = parser.parse_args()


def run_command(cmd, need_confirm=True):
    print("Command:", cmd)
    if not args.auto and need_confirm and input("Continue? (y/n): ") != "y":
        raise RuntimeError("User aborted.")
    if os.system(cmd) != 0:
        raise RuntimeError(f"Command failed: {cmd}")


cases = DataLoader.from_args(args, item_name="case")
print(f"You are going to run {len(cases)} cases.")
if not args.auto and input("Continue? (y/n): ") != "y":
    exit()

os.makedirs(args.dump_dir, exist_ok=True)
cmd = (
    f"python {EXECUTE_SCRIPT} -inp {args.input_path} -du {args.dump_dir} -outsuf _{NOW} "
    f"-atp {args.agent_type} -stp {args.simulator_type} -am {args.agent_model_name} -si {args.start_index}"
)
if args.trunc_num is not None:
    cmd += f"-tn {args.trunc_num}"
if args.batch_size is not None:
    cmd += f"-bs {args.batch_size}"
run_command(cmd)
output_path = os.path.join(
    args.dump_dir,
    f"traj_sim_{args.simulator_type}_agent_{args.agent_model_name}_{args.agent_type}_{NOW}",
)
print("The trajectories are saved to", output_path)

# evaluate all trajectories for different evaluators
cmd = f"python {EVALUATE_SCRIPT} -inp {output_path}.jsonl"
if args.batch_size is not None:
    cmd += f"-bs {args.batch_size}"
for ev in EVALUATORS.keys():
    run_command(f"{cmd} -ev {ev}")

# read evaluation results
run_command(f"python {READRESULTS_SCRIPT} {output_path}", need_confirm=False)
